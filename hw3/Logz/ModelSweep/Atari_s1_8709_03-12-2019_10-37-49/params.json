{"batch_size"	:	"32",
"double_q"	:	"True",
"env"	:	"<ClippedRewardsWrapper<ProcessFrame84<FireResetEnv<MaxAndSkipEnv<NoopResetEnv<EpisodicLifeEnv<Monitor<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>",
"exp_name"	:	"atari_model_s1",
"exploration"	:	"<dqn_utils.PiecewiseSchedule object at 0x7faa39462e80>",
"frame_history_len"	:	"4",
"gamma"	:	"0.99",
"grad_norm_clipping"	:	"10",
"lander"	:	"False",
"learning_freq"	:	"4",
"learning_starts"	:	"50000",
"logdir"	:	"Logz/ModelSweep/Atari_s1_8709_03-12-2019_10-37-49",
"optimizer_spec"	:	"OptimizerSpec(constructor=<class 'tensorflow.python.training.adam.AdamOptimizer'>, kwargs={'epsilon': 0.0001}, lr_schedule=<dqn_utils.PiecewiseSchedule object at 0x7faa39462e48>)",
"q_func"	:	"<function atari_model_s1 at 0x7faa39446510>",
"replay_buffer_size"	:	"1000000",
"rew_file"	:	"None",
"self"	:	"<dqn.QLearner object at 0x7faa39462eb8>",
"session"	:	"<tensorflow.python.client.session.Session object at 0x7faa39462a90>",
"stopping_criterion"	:	"<function atari_learn.<locals>.stopping_criterion at 0x7faa39446ea0>",
"target_update_freq"	:	"10000"}