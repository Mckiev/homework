{"batch_size"	:	"32",
"double_q"	:	"True",
"env"	:	"<ClippedRewardsWrapper<ProcessFrame84<FireResetEnv<MaxAndSkipEnv<NoopResetEnv<EpisodicLifeEnv<Monitor<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>",
"exp_name"	:	"atari_model_def256",
"exploration"	:	"<dqn_utils.PiecewiseSchedule object at 0x7f919094ee48>",
"frame_history_len"	:	"4",
"gamma"	:	"0.99",
"grad_norm_clipping"	:	"10",
"lander"	:	"False",
"learning_freq"	:	"4",
"learning_starts"	:	"50000",
"logdir"	:	"Logz/ModelSweep/Atari_def256_8856_04-12-2019_09-32-26",
"optimizer_spec"	:	"OptimizerSpec(constructor=<class 'tensorflow.python.training.adam.AdamOptimizer'>, kwargs={'epsilon': 0.0001}, lr_schedule=<dqn_utils.PiecewiseSchedule object at 0x7f919094ee10>)",
"q_func"	:	"<function atari_model_def256 at 0x7f91909336a8>",
"replay_buffer_size"	:	"1000000",
"rew_file"	:	"None",
"self"	:	"<dqn.QLearner object at 0x7f919094ee80>",
"session"	:	"<tensorflow.python.client.session.Session object at 0x7f919094ea58>",
"stopping_criterion"	:	"<function atari_learn.<locals>.stopping_criterion at 0x7f9190933ea0>",
"target_update_freq"	:	"10000"}