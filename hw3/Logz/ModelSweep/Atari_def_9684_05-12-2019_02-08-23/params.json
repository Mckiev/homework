{"batch_size"	:	"32",
"double_q"	:	"True",
"env"	:	"<ClippedRewardsWrapper<ProcessFrame84<FireResetEnv<MaxAndSkipEnv<NoopResetEnv<EpisodicLifeEnv<Monitor<TimeLimit<AtariEnv<PongNoFrameskip-v4>>>>>>>>>>",
"exp_name"	:	"atari_model_def",
"exploration"	:	"<dqn_utils.PiecewiseSchedule object at 0x7fcfbd7ace48>",
"frame_history_len"	:	"4",
"gamma"	:	"0.99",
"grad_norm_clipping"	:	"10",
"lander"	:	"False",
"learning_freq"	:	"4",
"learning_starts"	:	"50000",
"logdir"	:	"Logz/ModelSweep/Atari_def_9684_05-12-2019_02-08-23",
"optimizer_spec"	:	"OptimizerSpec(constructor=<class 'tensorflow.python.training.adam.AdamOptimizer'>, kwargs={'epsilon': 0.0001}, lr_schedule=<dqn_utils.PiecewiseSchedule object at 0x7fcfbd7ace10>)",
"q_func"	:	"<function atari_model_def at 0x7fd0258f3e18>",
"replay_buffer_size"	:	"1000000",
"rew_file"	:	"None",
"self"	:	"<dqn.QLearner object at 0x7fcfbd7ace80>",
"session"	:	"<tensorflow.python.client.session.Session object at 0x7fcfbd7aca58>",
"stopping_criterion"	:	"<function atari_learn.<locals>.stopping_criterion at 0x7fcfbd791ea0>",
"target_update_freq"	:	"10000"}